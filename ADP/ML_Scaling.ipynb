{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c50ab2",
   "metadata": {},
   "source": [
    "### 스케일링 작업 : 이상치 데이터로 분류의 정밀도가 낮아짐을 개선하기 위한 이유\n",
    "1. MinMaxScaler\n",
    "    - 0~1로 작업 -> 데이터 축소 작업이 되는것\n",
    "    - 이상치 값이 존재 할 경우 판단할 수 있는 값의 폭이 좁기 떄문에 판단이 모호하다. -> 그럴때 2번으로\n",
    "2. 표준화\n",
    "    - 평균을 0으로, 분산은 1로 만들어줌\n",
    "    - 특징량이 정규 분포인 경우 표준화된 특징량은 표준 정규 분포가 된다.\n",
    "3. 정규화\n",
    "    - 특징량을 정규화 (분산된 데이터를 어떤 일정한 범위에 가두는 것) 0~1, -1 ~1 사이로 가룬다.\n",
    "    \n",
    "- 머신러닝은 3단계 모두, 딥러닝은 바로 정규화로 넘어가는 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfb801",
   "metadata": {},
   "source": [
    "## Min-Max Scaling\n",
    "\n",
    "$$\n",
    "{\\tilde{x} = \\frac{x - min(x)}{max(x) - min(x)}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff81bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :  Listen Count    977.0\n",
      "dtype: float64\n",
      "min :  Listen Count    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd444444444\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# 1. 데이터 생성\n",
    "np.random.seed(100)\n",
    "data_array = []\n",
    "\n",
    "for i in range(1, 100):\n",
    "  s = np.random.randint(0, i * 10, 10)\n",
    "  data_array.extend(s)\n",
    "\n",
    "data_array.extend(np.zeros(100))\n",
    "\n",
    "# 2. 데이터 프레임으로 생성\n",
    "data = pd.DataFrame({'Listen Count': data_array})\n",
    "\n",
    "# 3. 최대값과 최소값을 리턴받자\n",
    "print(\"max : \",data.max()) # 977.0\n",
    "print(\"min : \",data.min()) # 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a94d55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "dtype: float64  ~ 0    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler() # 데이터를 줄인다. 0 ~ 1\n",
    "data_n = scaler.fit_transform(data) # 실행 후 배열의 객체로 리턴\n",
    "data_n = pd.DataFrame(data_n) # 프레임 생성\n",
    "\n",
    "print(data_n.max(),' ~', data_n.min()) ## 1.0 ~ 0으로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3899ed3",
   "metadata": {},
   "source": [
    "## 표준화 작업\n",
    "\n",
    "$$\n",
    "{\\tilde{x} = \\frac{x - mean(x)}{sqrt(var(x))}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad40a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listen Count    1.000918\n",
      "dtype: float64\n",
      "Listen Count    6.518741e-17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler # 표준화 작업 -> 너 이상치가 있어서 판단이 모호하구나? 그래서 표준화작업을 하는구나!\n",
    "\n",
    "# 데이터 생성\n",
    "\n",
    "np.random.seed(100)\n",
    "data_array = []\n",
    "for i in range(1, 100):\n",
    "  s = np.random.randint(0, i * 10, 10)\n",
    "  data_array.extend(s)\n",
    "\n",
    "data_array.extend(np.zeros(100))\n",
    "\n",
    "# 프레임 생성\n",
    "data = pd.DataFrame({'Listen Count': data_array})\n",
    "\n",
    "# 표준화 작업\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 표준화 실행 후 배열로 리턴\n",
    "data_n = scaler.fit_transform(data)\n",
    "\n",
    "# 데이터 프레임으로 재 생성\n",
    "data_n = pd.DataFrame({'Listen Count': data_n.ravel()})\n",
    "\n",
    "print(data_n.var()) ##1.000918\n",
    "print(data_n.mean()) ##6.518741e-17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac07e4",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\tilde{x} = \\frac{x}{||x||_2} \\\\\n",
    "||x||_2 = \\sqrt{x_1^2 + x_2^2+ ...+x_m^2 }\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344c5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "np.random.seed(100)\n",
    "data_array = []\n",
    "\n",
    "for i in range(1, 100):\n",
    "  s = np.random.randint(0, i * 10, 10)\n",
    "  data_array.extend(s)\n",
    "    \n",
    "data_array.extend(np.zeros(100))\n",
    "data = pd.DataFrame({'Listen Count': data_array})\n",
    "\n",
    "data_l2_normalized = normalize([data['Listen Count']],norm='l2')\n",
    "data_l2 = pd.DataFrame({'Listen Count': data_l2_normalized.ravel()})\n",
    "\n",
    "print(np.linalg.norm(data_l2_normalized,ord=2)) ## 0.999999999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05286a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
